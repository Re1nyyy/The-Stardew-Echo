import json
import os
import re
from typing import List, Dict, Any

# --- 1. è·¯å¾„å’Œé…ç½® (ä¸æ‚¨ä¹‹å‰è®¾ç½®çš„ç›¸åŒ) ---
WORLD_BOOK_PATH = 'book\worldbook.json'
CHARACTER_BOOK_PATH = 'book\characterbook.json'
INPUT_DIR = 'input_conversations' 
OUTPUT_DIR = 'train_data_alpaca'

# æ ¸å¿ƒé…ç½®ï¼šç©å®¶/ç”¨æˆ·çš„åç§°æ ‡è¯†
PLAYER_NAME = "team" 

# é€šç”¨ç³»ç»Ÿæç¤ºè¯ (ç”¨äºæ‰€æœ‰è§’è‰²ï¼Œç»“åˆRAGçŸ¥è¯†æ³¨å…¥)
SYSTEM_PROMPT_TEMPLATE = (
    "ä½ æ˜¯ä¸€ä¸ªèƒ½å¤Ÿè¿›è¡Œå¤šè§’è‰²æ‰®æ¼”çš„AIåŠ©æ‰‹ã€‚ä½ çš„ç›®æ ‡æ˜¯æ‰®æ¼”æ˜Ÿéœ²è°·ä¸­çš„ä¸€ä¸ªæŒ‡å®šè§’è‰²ï¼Œæ ¹æ®ç»™å®šçš„çŸ¥è¯†ã€å¯¹è¯å†å²ï¼Œä»¥é«˜ä¿çœŸçš„è§’è‰²å£å»ã€æƒ…ç»ªå’Œç«‹åœºè¿›è¡Œå›å¤ã€‚è¯·ä¸¥æ ¼éµå®ˆä¸–ç•Œè§‚ä¸­çš„äº¤æµå‡†åˆ™ã€‚\n"
    "--- è§’è‰²æ¡£æ¡ˆå’Œä¸–ç•Œè§‚å·²æ³¨å…¥ SYSTEM å­—æ®µï¼Œè¯·å‚é˜…ä¸‹æ–¹ ---"
)

# --------------------------
# 2. æ•°æ®åŠ è½½å‡½æ•° (ä¿æŒä¸å˜)
# --------------------------

def load_json_files(filepath: str) -> Dict[str, Any]:
    """å®‰å…¨åœ°è¯»å–æ™®é€š JSON æ–‡ä»¶å†…å®¹ (ç”¨äº worldbook/characterbook)"""
    if not os.path.exists(filepath):
        print(f"è­¦å‘Š: RAG çŸ¥è¯†æ–‡ä»¶æœªæ‰¾åˆ° - {filepath}ã€‚å°†ä½¿ç”¨ç©ºæ•°æ®ã€‚")
        return {}
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data
    except json.JSONDecodeError as e:
        print(f"é”™è¯¯: æ— æ³•è§£æ JSON æ–‡ä»¶ - {filepath}ã€‚è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€‚é”™è¯¯ä¿¡æ¯: {e}")
        return {}

def load_conversation_data(filepath: str) -> List[Dict[str, str]]:
    """è¯»å– JSON Lines æ–‡ä»¶å†…å®¹ï¼Œå¹¶æå– name å’Œ mes å­—æ®µ"""
    messages = []
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                
                data = json.loads(line)
                name = data.get('name')
                mes = data.get('mes')

                if not mes and data.get('swipes') and isinstance(data['swipes'], list) and data['swipes']:
                    mes = data['swipes'][0] # ä½¿ç”¨ç¬¬ä¸€ä¸ª swipe ä½œä¸º mes

                if data.get('is_system', False) or name in ["system", "System"]:
                    continue

                if name and mes:
                    messages.append({"name": name, "mes": mes})

    except json.JSONDecodeError as e:
        print(f"é”™è¯¯: æ— æ³•è§£æ JSON Lines æ–‡ä»¶ - {filepath}ã€‚è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€‚é”™è¯¯ä¿¡æ¯: {e}")
        return []
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return []
    
    return messages

# --------------------------
# 3. RAG Context æ„å»ºå‡½æ•° (ä¿æŒä¸å˜)
# --------------------------

def build_rag_context(worldbook_data: Dict, characterbook_data: Dict, active_names: List[str], target_char: str) -> str:
    """
    æ ¹æ®ä¸–ç•Œè§‚å’Œå½“å‰æ´»è·ƒè§’è‰²ï¼ŒåŠ¨æ€æ„å»º RAG Context æ¨¡æ¿ã€‚
    å¤„ç† SillyTavern Characterbook ç»“æ„ã€‚
    """
    
    context_parts = []
    all_char_entries = {}
    
    char_entries = characterbook_data.get('entries', {})
    if not char_entries:
        char_entries = worldbook_data.get('entries', {})

    if char_entries:
        for uid, entry in char_entries.items():
            if not isinstance(entry, dict):
                continue
            
            keys = entry.get('key', [])
            raw_content = entry.get('content', '').strip()
            
            if not keys or not raw_content:
                continue

            char_name = keys[0] 
            cleaned_content = raw_content.replace('```yaml', '').replace('```', '').strip()
            
            all_char_entries[char_name] = {
                'content': cleaned_content,
                'is_active': any(name in active_names for name in keys)
            }
        
    context_parts.append("### æ ¸å¿ƒè§’è‰²æ¡£æ¡ˆ (é•¿æœŸè®°å¿†)")
    
    # a. ç›®æ ‡è§’è‰²æ¡£æ¡ˆ (æ”¾åœ¨æœ€å‰é¢)
    if target_char in all_char_entries:
        target_entry = all_char_entries[target_char]['content']
        context_parts.append(f"ã€ä½ æ‰®æ¼”çš„è§’è‰²ï¼š{target_char}ã€‘\n{target_entry}\n")
        del all_char_entries[target_char] 
    else:
        context_parts.append(f"è­¦å‘Šï¼šæ‰¾ä¸åˆ°ç›®æ ‡è§’è‰² [{target_char}] çš„è¯¦ç»†æ¡£æ¡ˆã€‚")

    # b. æ´»è·ƒè§’è‰²çš„æ¡£æ¡ˆ
    active_other_chars = sorted([name for name, entry in all_char_entries.items() if entry['is_active']])
    
    for name in active_other_chars:
        entry = all_char_entries[name]
        context_parts.append(f"--- æ´»è·ƒè§’è‰²ï¼š{name} ---\n{entry['content']}\n")
                 
    context_parts.append("\n") 
    
    return "\n".join(context_parts)

# --------------------------
# 4. æ¸…æ´—å’Œ Alpaca æ ¼å¼åŒ–å‡½æ•° (ä¿æŒä¸å˜)
# --------------------------

def clean_message(text: str) -> str:
    """æ¸…ç†æ¶ˆæ¯ä¸­çš„ç‰¹æ®Šç¬¦å·å’Œå¤šä½™æ¢è¡Œç¬¦"""
    text = re.sub(r'\s*\n\s*', '\n', text).strip()
    return text

def format_history_alpaca(buffer: List[Dict], end_index: int) -> List[List[str]]:
    """
    å°†ç¼“å†²ä¸­çš„å¯¹è¯è½¬æ¢ä¸º Alpaca history æ ¼å¼: [["æŒ‡ä»¤", "å›ç­”"], ...]
    """
    history_list = []
    
    for i in range(0, end_index, 2):
        instruction_turn = buffer[i] if i < len(buffer) else None
        response_turn = buffer[i+1] if i+1 < len(buffer) else None
        
        if instruction_turn and response_turn:
            instruction = f"[{instruction_turn['name']}]: {clean_message(instruction_turn['mes'])}"
            response = f"[{response_turn['name']}]: {clean_message(response_turn['mes'])}"
            history_list.append([instruction, response])
            
    return history_list

def format_to_alpaca_jsonl(raw_messages: List[Dict], rag_context: str, target_char: str) -> List[Dict[str, Any]]:
    """å°†åŸå§‹ç¾¤èŠæ•°æ®æ ¼å¼åŒ–ä¸º LlamaFactory Alpaca (SFT) æ ¼å¼"""
    training_samples = []
    
    if len(raw_messages) < 2:
        return []
    
    final_system_content = f"{SYSTEM_PROMPT_TEMPLATE}\n\n### æ£€ç´¢åˆ°çš„é•¿æœŸè®°å¿†\n---\n{rag_context}"
    conversation_buffer = [] 
    
    for i, current_message in enumerate(raw_messages):
        speaker_name = current_message["name"]
        message_content = current_message["mes"]
        
        # æ‰¾åˆ°ç›®æ ‡è§’è‰²å›å¤ï¼Œå³ç”Ÿæˆä¸€ä¸ªè®­ç»ƒæ ·æœ¬
        if speaker_name == target_char and len(conversation_buffer) > 0:
            
            # --- 1. æå– Output ---
            output_content = clean_message(message_content)
            
            # --- 2. æå– Instruction/Input ---
            # ç›®æ ‡å›å¤çš„å‰ä¸€æ¡æ¶ˆæ¯æ˜¯ prompt
            prompt_turn = conversation_buffer[-1] 
            prompt_name = prompt_turn['name']
            
            # Instruction: Call to Actionï¼Œè¦æ±‚æ¨¡å‹æ‰®æ¼”ç›®æ ‡è§’è‰²å›å¤
            instruction = f"è¯·ä»¥ [{target_char}] çš„èº«ä»½å›å¤ä»¥ä¸‹æ¶ˆæ¯ã€‚"
            # Input: å®é™…çš„ prompt å†…å®¹ï¼ˆè¯´è¯äºº: æ¶ˆæ¯ï¼‰
            input_data = f"[{prompt_name}]: {clean_message(prompt_turn['mes'])}"
            
            # --- 3. æå– History ---
            # History æ˜¯ prompt_turn ä¹‹å‰çš„æ‰€æœ‰æ¶ˆæ¯
            history_list = format_history_alpaca(conversation_buffer, len(conversation_buffer) - 1)
            
            # --- 4. æ„å»º Alpaca è®­ç»ƒæ ·æœ¬ ---
            alpaca_sample = {
                "instruction": clean_message(instruction),
                "input": input_data,
                "output": output_content,
                "system": clean_message(final_system_content),
                "history": history_list
            }
            
            training_samples.append(alpaca_sample)
            
            # --- 5. æ›´æ–°ç¼“å†² ---
            # å°†ç›®æ ‡å›å¤åŠ å…¥ç¼“å†²ï¼Œä½œä¸ºä¸‹ä¸€è½®å†å²çš„èµ·ç‚¹
            conversation_buffer.append(current_message)
        
        else:
            # éç›®æ ‡è§’è‰²å‘è¨€ï¼ŒåŠ å…¥ç¼“å†²
            conversation_buffer.append(current_message)
            
        # æ¸…æ´—ï¼šå¯¹è¯å¤ªé•¿æ—¶è¿›è¡Œæˆªæ–­ï¼ˆé˜²æ­¢ history è¿‡é•¿ï¼‰
        if len(conversation_buffer) > 20: 
             conversation_buffer = conversation_buffer[-10:] 
            
    return training_samples

# --------------------------
# 5. å•ä¸ªæ–‡ä»¶å¤„ç†å‡½æ•°
# --------------------------

def process_single_conversation_file(
    input_filepath: str, 
    output_filepath_template: str, # æ¥æ”¶æ¨¡æ¿å­—ç¬¦ä¸²
    world_data: Dict, 
    char_data: Dict,
    target_char: str
):
    """å¤„ç†å•ä¸ªå¯¹è¯æ–‡ä»¶ï¼Œç”Ÿæˆ Alpaca æ ¼å¼æ•°æ®å¹¶ä¿å­˜"""
    
    # åŠ¨æ€ç”Ÿæˆç‰¹å®šè§’è‰²çš„è¾“å‡ºæ–‡ä»¶å
    output_filepath = output_filepath_template.format(target_char=target_char)
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è¯¥è§’è‰²çš„æ•°æ®ï¼Œé¿å…é‡å¤å¤„ç†
    if os.path.exists(output_filepath):
        # è­¦å‘Šï¼šè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå¦‚æœæ–‡ä»¶å·²å­˜åœ¨åˆ™è¿½åŠ æ•°æ®
        print(f"è­¦å‘Šï¼šæ–‡ä»¶ {output_filepath} å·²å­˜åœ¨ï¼Œæ–°æ ·æœ¬å°†è¿½åŠ åˆ°æ–‡ä»¶æœ«å°¾ã€‚")
        mode = 'a'
    else:
        mode = 'w'
    
    raw_messages = load_conversation_data(input_filepath)

    if not raw_messages:
        # print(f"âŒ æ–‡ä»¶ {os.path.basename(input_filepath)} ä¸­æœªåŠ è½½åˆ°æœ‰æ•ˆçš„å¯¹è¯è®°å½•ï¼Œè·³è¿‡ã€‚")
        return
    
    active_names = list(set([msg["name"] for msg in raw_messages]))
    
    rag_context = build_rag_context(world_data, char_data, active_names, target_char)

    jsonl_data = format_to_alpaca_jsonl(raw_messages, rag_context, target_char)

    if not jsonl_data:
        # print(f"âŒ æ–‡ä»¶ {os.path.basename(input_filepath)} æ— æ³•ç”Ÿæˆ {target_char} çš„è®­ç»ƒæ ·æœ¬ï¼Œè·³è¿‡ã€‚")
        return

    try:
        with open(output_filepath, mode, encoding='utf-8') as f:
            for sample in jsonl_data:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
        
        return len(jsonl_data)
    except Exception as e:
        print(f"ä¿å­˜æ–‡ä»¶ {output_filepath} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return 0


# --------------------------
# 6. ä¸»æ‰§è¡Œé€»è¾‘ (è‡ªåŠ¨éå†æ‰€æœ‰è§’è‰²)
# --------------------------

def main():
    print(f"å¯åŠ¨ Alpaca SFT æ•°æ®å¤„ç†å·¥å…· (å¤šè§’è‰²è‡ªåŠ¨éå†æ¨¡å¼)...")
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # 1. åŠ è½½ RAG çŸ¥è¯†æ–‡ä»¶
    world_data = load_json_files(WORLD_BOOK_PATH)
    char_data = load_json_files(CHARACTER_BOOK_PATH)
    
    # 2. ä»è§’è‰²ä¹¦è§£ææ‰€æœ‰éœ€è¦è®­ç»ƒçš„è§’è‰²åç§°
    all_target_chars = []
    char_entries = char_data.get('entries', {})
    for entry in char_entries.values():
        if entry.get('key'):
            # ä½¿ç”¨ç¬¬ä¸€ä¸ª key ä½œä¸ºè§’è‰²çš„æ ‡å‡†åç§°
            all_target_chars.append(entry['key'][0])
            
    if not all_target_chars:
        print("âŒ é”™è¯¯: æ— æ³•ä» characterbook.json ä¸­è§£æå‡ºä»»ä½•è§’è‰²åç§°ã€‚è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€‚")
        return

    print(f"æˆåŠŸè¯†åˆ« {len(all_target_chars)} ä¸ªç›®æ ‡è®­ç»ƒè§’è‰²: {', '.join(all_target_chars)}")
    
    # 3. å‡†å¤‡è¾“å…¥æ–‡ä»¶åˆ—è¡¨
    if not os.path.isdir(INPUT_DIR):
        print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶å¤¹ '{INPUT_DIR}' ä¸å­˜åœ¨ã€‚")
        return
        
    file_list = [f for f in os.listdir(INPUT_DIR) if f.endswith(('.json', '.jsonl'))]
    
    if not file_list:
        print(f"è­¦å‘Š: æ–‡ä»¶å¤¹ '{INPUT_DIR}' ä¸­æœªæ‰¾åˆ°ä»»ä½• .json æˆ– .jsonl æ–‡ä»¶ã€‚")
        return
        
    # 4. å¾ªç¯ï¼šä¸ºæ¯ä¸ªç›®æ ‡è§’è‰²å¤„ç†æ‰€æœ‰å¯¹è¯æ–‡ä»¶
    total_samples_generated = 0
    
    for target_char in all_target_chars:
        print("\n" + "=" * 50)
        print(f"ğŸš€ å¼€å§‹ä¸ºè§’è‰²ï¼šã€{target_char}ã€‘ç”Ÿæˆæ•°æ®...")
        
        char_sample_count = 0
        
        # æ„é€ è¾“å‡ºæ–‡ä»¶åæ¨¡æ¿ (ä½¿ç”¨ {target_char} å ä½ç¬¦)
        output_name = f"stardew_alpaca_{target_char}.jsonl"
        output_filepath_template = os.path.join(OUTPUT_DIR, output_name)
        
        # ç¡®ä¿è¾“å‡ºæ–‡ä»¶æ˜¯ç©ºçš„ï¼ˆæˆ–è€…ç§»é™¤ï¼Œè¿™é‡Œæˆ‘ä»¬é»˜è®¤è¦†ç›–/åˆ›å»ºæ–°æ–‡ä»¶ï¼Œä»¥é˜²å†å²è®°å½•æ··ä¹±ï¼‰
        if os.path.exists(output_filepath_template):
             os.remove(output_filepath_template)
             print(f"å·²æ¸…é™¤æ—§æ–‡ä»¶ï¼š{output_name}")


        for filename in file_list:
            input_filepath = os.path.join(INPUT_DIR, filename)
            
            # è°ƒç”¨å•ä¸ªæ–‡ä»¶å¤„ç†å‡½æ•°
            samples = process_single_conversation_file(
                input_filepath, 
                output_filepath_template, # ä¼ é€’æ¨¡æ¿
                world_data, 
                char_data,
                target_char 
            )
            char_sample_count += samples

        print(f"âœ… è§’è‰² ã€{target_char}ã€‘ æ•°æ®ç”Ÿæˆå®Œæˆã€‚å…±ç”Ÿæˆ {char_sample_count} ä¸ªæ ·æœ¬ã€‚")
        total_samples_generated += char_sample_count


    print("\n" + "=" * 50)
    print(f"ğŸ‰ æ‰€æœ‰ {len(all_target_chars)} ä¸ªè§’è‰²çš„æ•°æ®å¤„ç†å®Œæˆã€‚æ€»å…±ç”Ÿæˆäº† {total_samples_generated} ä¸ªè®­ç»ƒæ ·æœ¬ã€‚")
    print(f"æ•°æ®æ–‡ä»¶ä½äº '{OUTPUT_DIR}' æ–‡ä»¶å¤¹ä¸­ã€‚")
    print("=" * 50)


if __name__ == "__main__":
    main()